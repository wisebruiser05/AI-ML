{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a5ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a2011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b220a4c2-cf4a-49a0-97b0-047e6fdf9943",
       "rows": [
        [
         "id",
         "int64"
        ],
        [
         "age",
         "int64"
        ],
        [
         "job",
         "object"
        ],
        [
         "marital",
         "object"
        ],
        [
         "education",
         "object"
        ],
        [
         "default",
         "object"
        ],
        [
         "balance",
         "int64"
        ],
        [
         "housing",
         "object"
        ],
        [
         "loan",
         "object"
        ],
        [
         "contact",
         "object"
        ],
        [
         "day",
         "int64"
        ],
        [
         "month",
         "object"
        ],
        [
         "duration",
         "int64"
        ],
        [
         "campaign",
         "int64"
        ],
        [
         "pdays",
         "int64"
        ],
        [
         "previous",
         "int64"
        ],
        [
         "poutcome",
         "object"
        ],
        [
         "y",
         "int64"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 18
       }
      },
      "text/plain": [
       "id            int64\n",
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.dtypes\n",
    "df['job'].value_counts(normalize=True)\n",
    "# df.corr(method='spearman', numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr(numeric_only=True)\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "# plt.show()\n",
    "\n",
    "# print(corr_matrix)\n",
    "\n",
    "sns.pairplot(df, diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef904c4",
   "metadata": {},
   "source": [
    "##### Note\n",
    "Calculates both pearson and spearman correlation between all the columns -> 'duration' have the most correlation with the target value(y) (the value should be close to -1 or 1)\n",
    "Now find plot a graph between duration and y to find outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e76b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='duration', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['duration'].quantile(0.25)  # 25th percentile\n",
    "Q3 = df['duration'].quantile(0.75)  # 75th percentile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(\"Q1:\", Q1, \"Q3:\", Q3, \"IQR:\", IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e57cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['duration'] >= lower_bound) & (df['duration'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7980dba",
   "metadata": {},
   "source": [
    "##### Finding more outlier if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e920555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='balance', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with outliers\n",
    "sns.histplot(data=df, x='balance', kde=True)\n",
    "plt.title('Distribution with Outliers')\n",
    "plt.show()\n",
    "\n",
    "# Violin plot (combines box plot and density)\n",
    "# sns.violinplot(data=df, y='balance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind='hist')\n",
    "plt.suptitle('Pair Plot for Outlier Detection', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df.balance, data=df)\n",
    "# sns.boxplot(x=df.balance)\n",
    "plt.title('Box Plot to Detect Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Find outliers\n",
    "outliers, lower, upper = find_outliers_iqr(df, 'balance')\n",
    "\n",
    "# Visualize with highlighted outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x=df.index, y='balance', alpha=0.6)\n",
    "sns.scatterplot(data=outliers, x=outliers.index, y='balance', color='red', s=100)\n",
    "plt.axhline(y=lower, color='r', linestyle='--', alpha=0.7, label=f'Lower bound: {lower:.2f}')\n",
    "plt.axhline(y=upper, color='r', linestyle='--', alpha=0.7, label=f'Upper bound: {upper:.2f}')\n",
    "plt.legend()\n",
    "plt.title('Outliers Detection using IQR Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7258a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def find_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    outliers = df[z_scores > threshold]\n",
    "    return outliers\n",
    "\n",
    "# Find and visualize outliers\n",
    "outliers = find_outliers_zscore(df, 'balance')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x=df.index, y='balance', alpha=0.6)\n",
    "sns.scatterplot(data=outliers, x=outliers.index, y='balance', color='red', s=100)\n",
    "plt.title('Outliers Detection using Z-Score Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d3a28",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104b8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83445570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_cols = x.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "ct= ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ca29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoded = ct.fit_transform(x)\n",
    "x_scaled = scaler.fit_transform(x_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5483a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31512c6",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe60b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"Logistic regression model score = \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c27de",
   "metadata": {},
   "source": [
    "### Random Forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "rf_model = RandomForestClassifier(n_estimators=300,\n",
    "    max_depth=None,  # or try specific values like 10, 20\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "rf_y_pred = rf_model.predict(x_test)\n",
    "rf_y_pred_prob = rf_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Random Forest accuracy score: {acc}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, rf_y_pred_prob)\n",
    "print(f\"Random Forest ROC AUC: {roc_auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43031a94",
   "metadata": {},
   "source": [
    "### Random forest with gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54357832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=200)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=200))\n",
    "]\n",
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stack.fit(x_train, y_train)\n",
    "stack_y_pred = stack.predict(x_test)\n",
    "stack_y_pred_prob = stack.predict_proba(x_test)[:, 1]\n",
    "stack_acc = accuracy_score(y_test, stack_y_pred)\n",
    "stack_roc_auc = roc_auc_score(y_test, stack_y_pred_prob)\n",
    "print(f\"Stacking Classifier accuracy score: {stack_acc}\")\n",
    "print(f\"Stacking Classifier ROC AUC: {stack_roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec46e2",
   "metadata": {},
   "source": [
    "### Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ba54a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m gb_model.fit(x_train, y_train)\n\u001b[32m     10\u001b[39m gb_y_pred_prob = gb_model.predict_proba(x_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m gb_auc = \u001b[43mroc_auc_score\u001b[49m(y_test, gb_y_pred_prob)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGradient Boosting ROC AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgb_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "gb_y_pred_prob = gb_model.predict_proba(x_test)[:, 1]\n",
    "gb_auc = roc_auc_score(y_test, gb_y_pred_prob)\n",
    "print(f\"Gradient Boosting ROC AUC: {gb_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4e979",
   "metadata": {},
   "source": [
    "### RF + LigthGBM ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15013fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- Base models ---\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Stacking ensemble ---\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('lgb', lgb_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=200),\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "stack_model.fit(x_train, y_train)\n",
    "\n",
    "# --- Predict probabilities for ROC AUC ---\n",
    "stack_pred_prob = stack_model.predict_proba(x_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, stack_pred_prob)\n",
    "\n",
    "print(f\"Hybrid RF + LightGBM ROC AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78595ccd",
   "metadata": {},
   "source": [
    "### Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9296a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(x_train, y_train)\n",
    "nb_y_pred = nb_model.predict(x_test)\n",
    "nb_acc = roc_auc_score(y_test, nb_y_pred)\n",
    "print(f\"Naive Bayes ROC AUC: {nb_acc}\")\n",
    "\n",
    "nb_pred_prob = nb_model.predict_proba(x_test)[:, 1]\n",
    "nb_acc = roc_auc_score(y_test, nb_pred_prob)\n",
    "print(f\"Naive Bayes ROC AUC: {nb_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa22dc3",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb62662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "svm_model = LinearSVC(max_iter=1000, tol=1e-3)\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "svm_acc = roc_auc_score(y_test, svm_y_pred)\n",
    "print(f\"SVM ROC AUC: {svm_acc}\")\n",
    "\n",
    "svm_pred_prob = svm_model.decision_function(x_test)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_prob)\n",
    "print(f\"SVM ROC AUC: {svm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51cfeb",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc_model = SGDClassifier(loss='hinge', max_iter=1000)\n",
    "sgdc_model.fit(x_train, y_train)\n",
    "\n",
    "sgdc_y_pred = sgdc_model.predict(x_test)\n",
    "\n",
    "sgdc_acc = roc_auc_score(y_test, sgdc_y_pred)\n",
    "print(f\"SGD Classifier ROC AUC: {sgdc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b7942",
   "metadata": {},
   "source": [
    "### LightGBM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "x_train_lgb = lgb.Dataset(x_train, label=y_train)\n",
    "x_test_lgb = lgb.Dataset(x_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',  # or 'binary_logloss', 'auc', etc.\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(params, x_train_lgb, num_boost_round=1000, valid_sets=[x_train_lgb, x_test_lgb])\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration)\n",
    "# y_pred_class = [1 if p >= 0.5 else 0 for p in y_pred_lgb]\n",
    "\n",
    "lgb_auc = roc_auc_score(y_test, y_pred_lgb)\n",
    "print(f\"LightGBM ROC AUC: {lgb_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37731ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(x_train, y_train)\n",
    "lgb_pred_prob = lgb_model.predict_proba(x_test)[:, 1]\n",
    "print(\"LightGBM ROC AUC:\", roc_auc_score(y_test, lgb_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1c487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
